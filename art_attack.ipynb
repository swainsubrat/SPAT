{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 20:02:04.458594: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 20:02:04.633405: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-26 20:02:04.668191: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-26 20:02:05.504695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-26 20:02:05.504772: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-26 20:02:05.504779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%%capture installation\n",
    "\n",
    "\"\"\"\n",
    "A notebook created on 26th December, to edit the execute attack function for all the attacks.\n",
    "This is as per the new standard.\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from art.attacks.evasion import DeepFool, FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "from typing import Callable, Tuple, Dict\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "from dataloader import load_mnist\n",
    "from models.autoencoder import (ANNAutoencoder, BaseAutoEncoder,\n",
    "                                CelebAAutoencoder, CIFAR10Autoencoder, CIFAR10VAE,\n",
    "                                CIFAR10LightningAutoencoder)\n",
    "from models.classifier import (CelebAClassifier, CIFAR10Classifier,\n",
    "                                MNISTClassifier)\n",
    "\n",
    "from attacks import ATTACK_MAPPINGS\n",
    "from attacks.art_attack import get_models, get_xyz, hybridize\n",
    "from attacks.plot_attack import plot_adversarial_images, plot_robust_accuracy\n",
    "from dataloader import DATALOADER_MAPPINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 1\n",
    "    attack_name = \"hopskipjump\"\n",
    "    device  = \"cuda\"\n",
    "    model_name = \"cifar10_cnn_1\"\n",
    "    ae_name = \"cnn_256\"\n",
    "    plot = False\n",
    "    plot_dir = \"./plots\"\n",
    "    # kwargs = {\"batch_size\": 32, \"nb_grads\": 5, \"epsilon\": 1e-05} # deepfool\n",
    "    # kwargs = {\"eps\": 0.1} # pgd and fgsm\n",
    "    kwargs = {\"batch_size\": 30}\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture installation\n",
    "attack_name = ATTACK_MAPPINGS.get(args.attack_name)\n",
    "dataset_name = args.model_name.split(\"_\")[0]\n",
    "print(f\"Working on the dataset: {dataset_name}!!!!!\")\n",
    "\n",
    "with open(f\"./configs/{dataset_name}.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "classifier_model, autoencoder_model, config = get_models(args)\n",
    "print(f\"Loaded classifier and autoencoder models in eval mode!!!!!\")\n",
    "_, _, test_dataloader = DATALOADER_MAPPINGS[config[\"dataset_name\"]](batch_size=args.batch_size)\n",
    "print(f\"Loaded dataloader!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "Accuracy on benign test examples: 100.0%\n",
      "Accuracy on benign test examples(from reconstructed): 100.0%\n"
     ]
    }
   ],
   "source": [
    "x, y, z = get_xyz(args, autoencoder_model, test_dataloader)\n",
    "    \n",
    "config[\"latent_shape\"] = args.ae_name.split('_')[-1]\n",
    "classifier, hybrid_classifier, accuracy = hybridize(x, y, z, \n",
    "                                                    config, classifier_model, autoencoder_model)\n",
    "\n",
    "# Perform attack\n",
    "conditionals = {\n",
    "    \"calculate_original\": True,\n",
    "    \"is_class_constrained\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256) <class 'numpy.ndarray'>\n",
      "(1, 3, 32, 32) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,32,32) (100,32,32) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buq-cvl/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRobust accuracy of reconstructed adversarial attack: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(x_hat_adv_acc \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buq-cvl/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Buq-cvl/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m result: Dict \u001b[39m=\u001b[39m execute_attack(config, attack_name, x, y, z, classifier, hybrid_classifier, autoencoder_model, args\u001b[39m.\u001b[39;49mkwargs, conditionals)\n",
      "\u001b[1;32m/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb Cell 5\u001b[0m in \u001b[0;36mexecute_attack\u001b[0;34m(config, attack_name, x, y, z, classifier, hybrid_classifier, autoencoder_model, kwargs, conditionals)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buq-cvl/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m conditionals[\u001b[39m\"\u001b[39m\u001b[39mcalculate_original\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buq-cvl/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     attack \u001b[39m=\u001b[39m attack_name(classifier, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Buq-cvl/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     x_adv \u001b[39m=\u001b[39m attack\u001b[39m.\u001b[39;49mgenerate(x\u001b[39m=\u001b[39;49mx[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buq-cvl/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     predictions \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(x_test_adv_np)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Buq-cvl/home/sweta/gpu-top/Semantic-Preserving-Adversarial-Attack/art_attack.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     x_adv_acc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m y[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/py38/lib/python3.8/site-packages/art/attacks/evasion/hop_skip_jump.py:211\u001b[0m, in \u001b[0;36mHopSkipJump.generate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m         x_adv[ind] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_perturb(\n\u001b[1;32m    200\u001b[0m             x\u001b[39m=\u001b[39mval,\n\u001b[1;32m    201\u001b[0m             y\u001b[39m=\u001b[39my[ind],  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m             clip_max\u001b[39m=\u001b[39mclip_max,\n\u001b[1;32m    208\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m         x_adv[ind] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_perturb(\n\u001b[1;32m    212\u001b[0m             x\u001b[39m=\u001b[39;49mval,\n\u001b[1;32m    213\u001b[0m             y\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    214\u001b[0m             y_p\u001b[39m=\u001b[39;49mpreds[ind],\n\u001b[1;32m    215\u001b[0m             init_pred\u001b[39m=\u001b[39;49minit_preds[ind],\n\u001b[1;32m    216\u001b[0m             adv_init\u001b[39m=\u001b[39;49mx_adv_init[ind],\n\u001b[1;32m    217\u001b[0m             mask\u001b[39m=\u001b[39;49mmask[ind],\n\u001b[1;32m    218\u001b[0m             clip_min\u001b[39m=\u001b[39;49mclip_min,\n\u001b[1;32m    219\u001b[0m             clip_max\u001b[39m=\u001b[39;49mclip_max,\n\u001b[1;32m    220\u001b[0m         )\n\u001b[1;32m    222\u001b[0m y \u001b[39m=\u001b[39m to_categorical(y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mnb_classes)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    224\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    225\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSuccess rate of HopSkipJump attack: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m     \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m compute_success(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator, x, y, x_adv, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargeted, batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size),\n\u001b[1;32m    227\u001b[0m )\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/py38/lib/python3.8/site-packages/art/attacks/evasion/hop_skip_jump.py:265\u001b[0m, in \u001b[0;36mHopSkipJump._perturb\u001b[0;34m(self, x, y, y_p, init_pred, adv_init, mask, clip_min, clip_max)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m    264\u001b[0m \u001b[39m# If an initial adversarial example found, then go with HopSkipJump attack\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m x_adv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attack(initial_sample[\u001b[39m0\u001b[39;49m], x, initial_sample[\u001b[39m1\u001b[39;49m], mask, clip_min, clip_max)\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m x_adv\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/py38/lib/python3.8/site-packages/art/attacks/evasion/hop_skip_jump.py:422\u001b[0m, in \u001b[0;36mHopSkipJump._attack\u001b[0;34m(self, initial_sample, original_sample, target, mask, clip_min, clip_max)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[39m# Next compute the number of evaluations and compute the update\u001b[39;00m\n\u001b[1;32m    420\u001b[0m num_eval \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_eval \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr_iter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_eval)\n\u001b[0;32m--> 422\u001b[0m update \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_update(\n\u001b[1;32m    423\u001b[0m     current_sample\u001b[39m=\u001b[39;49mcurrent_sample,\n\u001b[1;32m    424\u001b[0m     num_eval\u001b[39m=\u001b[39;49mnum_eval,\n\u001b[1;32m    425\u001b[0m     delta\u001b[39m=\u001b[39;49mdelta,\n\u001b[1;32m    426\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    427\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    428\u001b[0m     clip_min\u001b[39m=\u001b[39;49mclip_min,\n\u001b[1;32m    429\u001b[0m     clip_max\u001b[39m=\u001b[39;49mclip_max,\n\u001b[1;32m    430\u001b[0m )\n\u001b[1;32m    432\u001b[0m \u001b[39m# Finally run step size search by first computing epsilon\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/scratch/miniconda3/envs/py38/lib/python3.8/site-packages/art/attacks/evasion/hop_skip_jump.py:605\u001b[0m, in \u001b[0;36mHopSkipJump._compute_update\u001b[0;34m(self, current_sample, num_eval, delta, target, mask, clip_min, clip_max)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[39m# Normalize random noise to fit into the range of input data\u001b[39;00m\n\u001b[1;32m    598\u001b[0m rnd_noise \u001b[39m=\u001b[39m rnd_noise \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msqrt(\n\u001b[1;32m    599\u001b[0m     np\u001b[39m.\u001b[39msum(\n\u001b[1;32m    600\u001b[0m         rnd_noise \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m     )\n\u001b[1;32m    604\u001b[0m )\n\u001b[0;32m--> 605\u001b[0m eval_samples \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(current_sample \u001b[39m+\u001b[39;49m delta \u001b[39m*\u001b[39;49m rnd_noise, clip_min, clip_max)\n\u001b[1;32m    606\u001b[0m rnd_noise \u001b[39m=\u001b[39m (eval_samples \u001b[39m-\u001b[39m current_sample) \u001b[39m/\u001b[39m delta\n\u001b[1;32m    608\u001b[0m \u001b[39m# Compute gradient: This is a bit different from the original paper, instead we keep those that are\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39m# implemented in the original source code of the authors\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,32,32) (100,32,32) "
     ]
    }
   ],
   "source": [
    "def execute_attack(config, attack_name, x, y, z, classifier, hybrid_classifier, autoencoder_model, kwargs, conditionals):\n",
    "    result = {}\n",
    "    name = attack_name.__name__\n",
    "    result[name] = {}\n",
    "    \n",
    "    print(z[1].shape, type(z[1]))\n",
    "    print(x[1].shape, type(x[1]))\n",
    "    # ------------------------------------------------- #\n",
    "    # ---------------- Original Attack ---------------- #\n",
    "    # ------------------------------------------------- #\n",
    "    if conditionals[\"calculate_original\"]:\n",
    "        attack = attack_name(classifier, **kwargs)\n",
    "        x_adv = attack.generate(x=x[1])\n",
    "        predictions = classifier.predict(x_test_adv_np)\n",
    "        x_adv_acc = np.sum(np.argmax(predictions, axis=-1) == y[1]) / len(y[1])\n",
    "\n",
    "        result[name][\"x_adv\"] = x_adv\n",
    "        result[name][\"x_adv_acc\"] = x_adv_acc\n",
    "\n",
    "        # calculate noise\n",
    "        delta_x = x_test_adv_np - x[1]\n",
    "        result[name][\"delta_x\"] = delta_x\n",
    "        print(\"Robust accuracy of original adversarial attack: {}%\".format(accuracy * 100))\n",
    "\n",
    "    # ------------------------------------------------- #\n",
    "    # ---------------- Modified Attack ---------------- #\n",
    "    # ------------------------------------------------- #\n",
    "    print(attack_name)\n",
    "    modified_attack = attack_name(hybrid_classifier, **kwargs)\n",
    "    if conditionals[\"is_class_constrained\"]:\n",
    "        z_adv = modified_attack.generate(x=z[1], mask=generate_mask(\n",
    "            latent_dim=int(config[\"latent_shape\"]),\n",
    "            n_classes=config[\"miscs\"][\"nb_classes\"],\n",
    "            labels=y[1]))\n",
    "    else:\n",
    "        z_adv = modified_attack.generate(x=z[1])\n",
    "\n",
    "    # calculate noise\n",
    "    x_hat_adv   = autoencoder_model.decoder(torch.Tensor(z_adv).to(config[\"device\"]))\n",
    "    x_hat       = autoencoder_model.decoder(torch.Tensor(z[1]).to(config[\"device\"]))\n",
    "    delta_x_hat  = x_hat_adv - x_hat\n",
    "\n",
    "    # modified attack\n",
    "    modf_x_adv   = x[1] + delta_x_hat.cpu().detach().numpy()\n",
    "    predictions = classifier.predict(modf_x_adv)\n",
    "    modf_x_adv_acc = np.sum(np.argmax(predictions, axis=-1) == y[1]) / len(y[1])\n",
    "\n",
    "    result[name][\"modf_x_adv\"] = modf_x_adv\n",
    "    result[name][\"modf_x_adv_acc\"] = modf_x_adv_acc\n",
    "\n",
    "    # reconstructed attack\n",
    "    predictions = hybrid_classifier.predict(z_adv)\n",
    "    x_hat_adv_acc = np.sum(np.argmax(predictions, axis=-1) == y[1]) / len(y[1])\n",
    "\n",
    "    result[name][\"z_adv\"] = z_adv\n",
    "    result[name][\"x_hat_adv\"] = x_hat_adv.cpu().detach().numpy()\n",
    "    result[name][\"x_hat_adv_acc\"] = x_hat_adv_acc\n",
    "    \n",
    "    # send combined noise\n",
    "    result[name][\"delta_x_hat\"] = delta_x_hat.cpu().detach().numpy()\n",
    "\n",
    "    print(\"Robust accuracy of modified adversarial attack: {}%\".format(modf_x_adv_acc * 100))\n",
    "    print(\"Robust accuracy of reconstructed adversarial attack: {}%\".format(x_hat_adv_acc * 100))\n",
    "\n",
    "    return result\n",
    "\n",
    "result: Dict = execute_attack(config, attack_name, x, y, z, classifier, hybrid_classifier, autoencoder_model, args.kwargs, conditionals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.models import load_model\n",
    "\n",
    "from art import config\n",
    "from art.utils import load_dataset, get_file\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import BasicIterativeMethod\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = get_file('mnist_cnn_robust.h5', extract=False, path=config.ART_DATA_PATH,\n",
    "                url='https://www.dropbox.com/s/yutsncaniiy5uy8/mnist_cnn_robust.h5?dl=1')\n",
    "robust_classifier_model = load_model(path)\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset('mnist')\n",
    "robust_classifier = KerasClassifier(clip_values=(min_, max_), model=robust_classifier_model, use_logits=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2061b166dac01908a0f4a5ba1d22c95daad8f159675dc38080e034f724a8b94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
