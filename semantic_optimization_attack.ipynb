{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture installation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from art.attacks.evasion import DeepFool, FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "from typing import Callable, Tuple, Dict\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "from dataloader import load_mnist\n",
    "from models.autoencoder import (ANNAutoencoder, BaseAutoEncoder,\n",
    "                                CelebAAutoencoder, CIFAR10Autoencoder)\n",
    "from models.classifier import (CelebAClassifier, CIFAR10Classifier,\n",
    "                                MNISTClassifier)\n",
    "\n",
    "from attacks import ATTACK_MAPPINGS\n",
    "from attacks.art_attack import execute_attack, get_models, get_xyz, hybridize\n",
    "from attacks.plot_attack import plot_adversarial_images, plot_robust_accuracy\n",
    "from dataloader import DATALOADER_MAPPINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 1\n",
    "    device  = \"mps\"\n",
    "    model_name = \"cifar10_cnn_1\"\n",
    "    ae_name = \"ann_128\"\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on the dataset: cifar10!!!!!\n",
      "Loaded classifier and autoencoder models in eval mode!!!!!\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loaded dataloader cifar10!!!!!\n"
     ]
    }
   ],
   "source": [
    "dataset_name = args.model_name.split(\"_\")[0]\n",
    "print(f\"Working on the dataset: {dataset_name}!!!!!\")\n",
    "\n",
    "with open(f\"./configs/{dataset_name}.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "classifier_model, autoencoder_model, config = get_models(args)\n",
    "print(f\"Loaded classifier and autoencoder models in eval mode!!!!!\")\n",
    "_, valid_dataloader, test_dataloader = DATALOADER_MAPPINGS[config[\"dataset_name\"]](batch_size=args.batch_size)\n",
    "print(f\"Loaded dataloader {config['dataset_name']}!!!!!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adversarial_images(images, pgd_adv_images, spgd_adv_images, reshape_size=(28, 28)):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1,5,1, xticks=[], yticks=[])\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(images[0].cpu().detach().reshape(reshape_size))\n",
    "\n",
    "    plt.subplot(1,5,2, xticks=[], yticks=[])\n",
    "    plt.title(\"PGD\")\n",
    "    plt.imshow(pgd_adv_images[0].cpu().detach().reshape(reshape_size))\n",
    "\n",
    "    pgd_noise = pgd_adv_images[0] - images[0]\n",
    "    plt.subplot(1,5,3, xticks=[], yticks=[])\n",
    "    plt.title(\"PGD Noise\")\n",
    "    plt.imshow(pgd_noise.cpu().detach().reshape(reshape_size))\n",
    "\n",
    "    plt.subplot(1,5,4, xticks=[], yticks=[])\n",
    "    plt.title(\"SemanticPGD\")\n",
    "    plt.imshow(spgd_adv_images[0].cpu().detach().reshape(reshape_size))\n",
    "\n",
    "    spgd_noise = spgd_adv_images[0] - images[0]\n",
    "    plt.subplot(1,5,5, xticks=[], yticks=[])\n",
    "    plt.title(\"SemanticPGD Noise\")\n",
    "    plt.imshow(spgd_noise.cpu().detach().reshape(reshape_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels, eps=0.3, alpha=2/255, iters=40) :\n",
    "    images = images.to(args.device)\n",
    "    labels = labels.to(args.device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    ori_images = images.data\n",
    "        \n",
    "    for i in range(iters) :  \n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "\n",
    "        model.zero_grad()\n",
    "        cost = loss(outputs, labels).to(args.device)\n",
    "        cost.backward()\n",
    "\n",
    "        # Perturb original image\n",
    "        adv_images = images + alpha*images.grad.sign()\n",
    "\n",
    "        eta = torch.clamp(adv_images - ori_images, min=-eps, max=eps)\n",
    "        images = torch.clamp(ori_images + eta, min=0, max=1).detach_()\n",
    "            \n",
    "    return images\n",
    "\n",
    "def semantic_pgd_attack(model, ae_model, images, labels, eps=0.4, alpha=3/255, s_alpha=0.007, iters=40, batch_size=1) :\n",
    "    images = images.to(args.device)\n",
    "    labels = labels.to(args.device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    adv_images = images.clone().detach()\n",
    "    original_inputs_numpy = images.clone().cpu().detach().numpy()\n",
    "        \n",
    "    for i in range(iters) :\n",
    "        adv_images.requires_grad = True\n",
    "        # adv_images = adv_images.to(args.device)\n",
    "        \n",
    "        # Classifier part\n",
    "        outputs = model(adv_images)\n",
    "\n",
    "        model.zero_grad()\n",
    "        cost = loss(outputs, labels).to(args.device)\n",
    "        cost.backward()\n",
    "\n",
    "        # # Perturb original image\n",
    "        # adv_images = images + alpha*images.grad.sign()\n",
    "\n",
    "        # # Adjust semantics\n",
    "        # adv_images = adv_images.detach_()\n",
    "        # adv_images.requires_grad = True\n",
    "        # recon_images, _ = ae_model(adv_images)\n",
    "        # ae_model.zero_grad()\n",
    "\n",
    "        # Calculate grad w.r.t classifier\n",
    "        grad_classifier = adv_images.grad.cpu().detach()\n",
    "\n",
    "        # Autoencoder part\n",
    "        adv_images.grad = None\n",
    "        recon_images, _ = ae_model(adv_images)\n",
    "        ae_model.zero_grad()\n",
    "\n",
    "        mse_loss = F.mse_loss(adv_images, recon_images).to(args.device)\n",
    "        mse_loss.backward()\n",
    "\n",
    "        # Calculate grad w.r.t autoencoder\n",
    "        grad_autoencoder = adv_images.grad.cpu().detach()\n",
    "\n",
    "        # Check if the attack is successful\n",
    "        has_attack_succeeded = (outputs.cpu().detach().numpy().argmax(1)!=labels.cpu().numpy())\n",
    "\n",
    "        # Calculate the projection of perceptual grad on classifier\n",
    "        # and grad_autoencoder = grad_autoencoder - (projection of gradient_autoencoder onto gradient_classifier)\n",
    "        grad_autoencoder_proj = grad_autoencoder - torch.bmm((torch.bmm(grad_autoencoder.view(batch_size, 1, -1), \n",
    "                                grad_classifier.view(batch_size, -1, 1)))/(1e-20+torch.bmm(grad_classifier.view(batch_size, 1, -1),\n",
    "                                grad_classifier.view(batch_size, -1, 1))).view(-1, 1, 1),\n",
    "                                grad_classifier.view(batch_size, 1, -1)).view(grad_autoencoder.shape)\n",
    "\n",
    "        # Calculate the projection of classifier grad on autoencoder\n",
    "        # and grad_classifier = grad_classifier - (projection of gradient_classifier onto gradient_autoencoder)\n",
    "        grad_classifier_proj = grad_classifier - torch.bmm((torch.bmm(grad_classifier.view(batch_size, 1, -1),\n",
    "                               grad_autoencoder.view(batch_size, -1, 1)))/(1e-20+torch.bmm(grad_autoencoder.view(batch_size, 1, -1),\n",
    "                               grad_autoencoder.view(batch_size, -1, 1))).view(-1, 1, 1),\n",
    "                               grad_autoencoder.view(batch_size, 1, -1)).view(grad_classifier.shape)\n",
    "\n",
    "        # Combine grads (Selective Gradient Descent)\n",
    "        # grad = grad_classifier * (1-has_attack_succeeded) - grad_autoencoder * has_attack_succeeded\n",
    "        grad = grad_classifier_proj * (1-has_attack_succeeded) - (grad_autoencoder_proj) * has_attack_succeeded\n",
    "\n",
    "        # Add semantic perturbation\n",
    "        # adv_examples = adv_images - s_alpha * sign_data_grad\n",
    "\n",
    "        # Apply combined perturbation\n",
    "        sign_grad = torch.sign(grad).to(torch.float32).to(args.device)\n",
    "        adv_images = adv_images.detach() + alpha * sign_grad\n",
    "\n",
    "        eta = torch.clamp(adv_images - torch.tensor(original_inputs_numpy).to(args.device), min=-eps, max=eps)\n",
    "        adv_images = torch.clamp(torch.tensor(original_inputs_numpy).to(args.device) + eta, min=0, max=1).detach()\n",
    "            \n",
    "    return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of validation dataloader: 10000\n",
      "Accuracy of test pgd : 0.000000 %\n",
      "Accuracy of test spgd: 50.000000 %\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 32, 32) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy of test pgd : \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m(pgd_correct) \u001b[38;5;241m/\u001b[39m (total)))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy of test spgd: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m(spgd_correct) \u001b[38;5;241m/\u001b[39m (total)))\n\u001b[0;32m---> 31\u001b[0m \u001b[43mplot_adversarial_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpgd_adv_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspgd_adv_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreshape_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [13], line 5\u001b[0m, in \u001b[0;36mplot_adversarial_images\u001b[0;34m(images, pgd_adv_images, spgd_adv_images, reshape_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m, xticks\u001b[38;5;241m=\u001b[39m[], yticks\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshape_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m, xticks\u001b[38;5;241m=\u001b[39m[], yticks\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPGD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/_api/deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    449\u001b[0m     warn_deprecated(\n\u001b[1;32m    450\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/pyplot.py:2623\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2617\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mimshow)\n\u001b[1;32m   2618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(\n\u001b[1;32m   2619\u001b[0m         X, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, aspect\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, interpolation\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2620\u001b[0m         alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, origin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, extent\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m   2621\u001b[0m         interpolation_stage\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, filternorm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, filterrad\u001b[39m=\u001b[39m\u001b[39m4.0\u001b[39m,\n\u001b[1;32m   2622\u001b[0m         resample\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2623\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mimshow(\n\u001b[1;32m   2624\u001b[0m         X, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm, aspect\u001b[39m=\u001b[39;49maspect,\n\u001b[1;32m   2625\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation, alpha\u001b[39m=\u001b[39;49malpha, vmin\u001b[39m=\u001b[39;49mvmin,\n\u001b[1;32m   2626\u001b[0m         vmax\u001b[39m=\u001b[39;49mvmax, origin\u001b[39m=\u001b[39;49morigin, extent\u001b[39m=\u001b[39;49mextent,\n\u001b[1;32m   2627\u001b[0m         interpolation_stage\u001b[39m=\u001b[39;49minterpolation_stage,\n\u001b[1;32m   2628\u001b[0m         filternorm\u001b[39m=\u001b[39;49mfilternorm, filterrad\u001b[39m=\u001b[39;49mfilterrad, resample\u001b[39m=\u001b[39;49mresample,\n\u001b[1;32m   2629\u001b[0m         url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}),\n\u001b[1;32m   2630\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2631\u001b[0m     sci(__ret)\n\u001b[1;32m   2632\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/_api/deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    449\u001b[0m     warn_deprecated(\n\u001b[1;32m    450\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1422\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1425\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1426\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1427\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/axes/_axes.py:5604\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5596\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5597\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm,\n\u001b[1;32m   5598\u001b[0m                       interpolation\u001b[39m=\u001b[39minterpolation, origin\u001b[39m=\u001b[39morigin,\n\u001b[1;32m   5599\u001b[0m                       extent\u001b[39m=\u001b[39mextent, filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[1;32m   5600\u001b[0m                       filterrad\u001b[39m=\u001b[39mfilterrad, resample\u001b[39m=\u001b[39mresample,\n\u001b[1;32m   5601\u001b[0m                       interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5602\u001b[0m                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 5604\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[1;32m   5605\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5606\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5607\u001b[0m     \u001b[39m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/matplotlib/image.py:710\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m    708\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]):\n\u001b[0;32m--> 710\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for image data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    711\u001b[0m                     \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    713\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    714\u001b[0m     \u001b[39m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    715\u001b[0m     \u001b[39m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[39m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[39m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     high \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 32, 32) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pgd_correct = 0\n",
    "spgd_correct = 0\n",
    "total = 0\n",
    "\n",
    "print(f\"Length of validation dataloader: {len(test_dataloader)}\")\n",
    "\n",
    "for i, (images, labels) in enumerate(test_dataloader):\n",
    "    labels = labels.to(args.device)\n",
    "    images = images.to(args.device)\n",
    "\n",
    "    pgd_adv_images = pgd_attack(classifier_model, images, labels)\n",
    "    spgd_adv_images = semantic_pgd_attack(classifier_model, autoencoder_model, images, labels)\n",
    "    \n",
    "    pgd_outputs = classifier_model(pgd_adv_images)\n",
    "    spgd_outputs = classifier_model(spgd_adv_images)\n",
    "    \n",
    "    _, pgd_pre = torch.max(pgd_outputs.data, 1)\n",
    "    _, spgd_pre = torch.max(spgd_outputs.data, 1)\n",
    "\n",
    "    total += 1\n",
    "    pgd_correct += (pgd_pre == labels).sum()\n",
    "    spgd_correct += (spgd_pre == labels).sum()\n",
    "    if i == 5:\n",
    "        break\n",
    "    \n",
    "    # plt.imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])\n",
    "    \n",
    "print('Accuracy of test pgd : %f %%' % (100 * float(pgd_correct) / (total)))\n",
    "print('Accuracy of test spgd: %f %%' % (100 * float(spgd_correct) / (total)))\n",
    "\n",
    "plot_adversarial_images(images, pgd_adv_images, spgd_adv_images, reshape_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision\n",
    "def plot_images(images):\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    images = torch.Tensor(images).reshape(-1, 3, 32, 32)\n",
    "    grid = torchvision.utils.make_grid(images, nrow=10, normalize=True, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "images = images.cpu().detach()\n",
    "pgd_adv_images = pgd_adv_images.cpu().detach()\n",
    "spgd_adv_images = spgd_adv_images.cpu().detach()\n",
    "\n",
    "plot_images(torch.stack([images, pgd_adv_images, spgd_adv_images]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b39706cd669bce428b01e7d8e16fbcdbe71050c908092321457055cd8ee4a18a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
